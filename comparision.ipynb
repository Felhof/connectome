{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "import core\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Models\n",
    "gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "attn_only_4l = HookedTransformer.from_pretrained(\"attn-only-4l\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Task:\n",
    "    model: HookedTransformer\n",
    "    prompt: str\n",
    "    corrupted: list[str]\n",
    "    correct: str\n",
    "    incorrect: list[str]\n",
    "    short_name: str\n",
    "\n",
    "    @property\n",
    "    def metric(self):\n",
    "        return core.logit_diff_metric(self.model, self.correct, *self.incorrect)\n",
    "\n",
    "    def tokens(self):\n",
    "        return self.model.to_str_tokens(self.prompt)\n",
    "\n",
    "    def pos_and_tokens(self):\n",
    "        return [f\"{i}: {t}\" for i, t in enumerate(self.tokens())]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task_ioi_ABBA = Task(\n",
    "    model=gpt2,\n",
    "    prompt=\"When Mary and John went to the store, John gave a book to\",\n",
    "    correct=\" Mary\",\n",
    "    incorrect=[\" John\"],\n",
    "    corrupted=[\n",
    "        \"When Felix and Sarah went to the store, Diego gave a book to\",\n",
    "        \"When Sarah and Felix went to the store, Felix gave a book to\",\n",
    "        \"When Paul and John went to the store, John gave a book to\",\n",
    "        \"When Mary and Felix went to the store, Diego gave a book to\",\n",
    "    ],\n",
    "    short_name=\"ioi_abba\",\n",
    ")\n",
    "\n",
    "task_ioi_BABA = Task(\n",
    "    model=gpt2,\n",
    "    prompt=\"When John and Mary went to the store, John gave a book to\",\n",
    "    correct=\" Mary\",\n",
    "    incorrect=[\" John\"],\n",
    "    corrupted=[\n",
    "        \"When Felix and Sarah went to the store, Diego gave a book to\",\n",
    "        \"When Felix and Sarah went to the store, Felix gave a book to\",\n",
    "        \"When John and Paul went to the store, John gave a book to\",\n",
    "        \"When Diego and Mary went to the store, Felix gave a book to\",\n",
    "    ],\n",
    "    short_name=\"ioi_baba\",\n",
    ")\n",
    "task_docstring = Task(\n",
    "    model=attn_only_4l,\n",
    "    prompt='''def port(self, load, size, file, last):\n",
    "    \"\"\"oil column piece\n",
    "\n",
    "    :param load: crime population\n",
    "    :param size: unit dark\n",
    "    :param''',\n",
    "    correct=\" file\",\n",
    "    incorrect=[\" last\", \" load\", \" size\", \" self\"],\n",
    "    corrupted=[],  # TODO: fill in\n",
    "    short_name=\"docstring 1\",\n",
    ")\n",
    "task_docstring_2 = Task(\n",
    "    model=attn_only_4l,\n",
    "    prompt='''def run(place, nb, last, first):\n",
    "    \"\"\"run the place\n",
    "\n",
    "    :param place: place to run\n",
    "    :param nb: number of times to run\n",
    "    :param''',\n",
    "    correct=\" first\",\n",
    "    incorrect=[\" last\", \" place\", \" nb\"],\n",
    "    corrupted=[],  # TODO: fill in\n",
    "    short_name=\"docstring 2\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TOP_K = 10\n",
    "TASKS = [task_ioi_ABBA]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for task in TASKS:\n",
    "    assert task.metric(task.model(task.prompt)[0]) > 0.1, \"The model cannot do the task\"\n",
    "    interventions = [\n",
    "        core.ZeroPattern(),\n",
    "        core.DampenIntervention(0.1),\n",
    "        core.DampenIntervention(0.3),\n",
    "        core.CropIntervention(task.model, task.prompt),\n",
    "    ]\n",
    "    # for corrupted in task.corrupted:\n",
    "    #     interventions.append(core.CorruptIntervention(task.model, task.prompt, corrupted))\n",
    "\n",
    "    strategy = core.BasicStrategy()\n",
    "    for intervention in interventions:\n",
    "        connectome = core.connectom(\n",
    "            task.model, task.prompt, task.metric, intervention, strategy\n",
    "        )\n",
    "        print(task.short_name)\n",
    "        print(task.prompt)\n",
    "        print(\"Correct: \", task.correct)\n",
    "        print(\"Incorrect: \", task.incorrect)\n",
    "        print(\"Intervention: \", intervention)\n",
    "        core.plot_graphviz_connectome(task.model, task.prompt, connectome, top_k=TOP_K)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing Dampening Interventions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task = task_ioi_ABBA\n",
    "connectomes = []\n",
    "alphas = list(range(10)) + [-10, -5, 15, 20]\n",
    "for alpha in alphas:\n",
    "    intervention = core.DampenIntervention(alpha / 10)\n",
    "    strategy = core.BasicStrategy()\n",
    "    connectome = core.connectom(\n",
    "        task.model, task.prompt, task.metric, intervention, strategy\n",
    "    )\n",
    "    connectomes.append(connectome)\n",
    "    print(task.short_name, \"dampening\", alpha / 10)\n",
    "    core.plot_graphviz_connectome(task.model, task.prompt, connectome, top_k=TOP_K)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var = torch.stack(\n",
    "    [core.attn_connectome(task.model, task.prompt, c, fill=0) for c in connectomes]\n",
    ")\n",
    "# var = var / torch.linalg.matrix_norm(var, keepdim=True)\n",
    "var = var / var.max(dim=2, keepdim=True).values.max(dim=1, keepdim=True).values\n",
    "px.imshow(\n",
    "    var.std(0),\n",
    "    x=task.pos_and_tokens(),\n",
    "    y=task.pos_and_tokens(),\n",
    "    color_continuous_scale=\"Blues\",\n",
    "    title=\"Std. dev. of normalised connexions\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ~Sanity check\n",
    "for task in [task_ioi_ABBA, task_ioi_BABA]:\n",
    "    _, cache = task.model.run_with_cache(task.prompt)\n",
    "    avg_attention = (\n",
    "        torch.stack(\n",
    "            [\n",
    "                cache[\"pattern\", layer][0]  # remove batch dim\n",
    "                for layer in range(task.model.cfg.n_layers)\n",
    "            ]\n",
    "        )\n",
    "        .max(dim=0)\n",
    "        .values.max(dim=0)\n",
    "        .values\n",
    "    )  # max over heads and layer\n",
    "\n",
    "    px.imshow(\n",
    "        avg_attention,\n",
    "        x=task.pos_and_tokens(),\n",
    "        y=task.pos_and_tokens(),\n",
    "        color_continuous_scale=\"Blues\",\n",
    "        title=\"Max attention on \" + task.short_name,\n",
    "    ).show()\n",
    "    # %%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing contrastive connectomes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task = task_ioi_ABBA\n",
    "for corrupt in task.corrupted:\n",
    "    intervention = core.CorruptIntervention(task.model, task.prompt, corrupt)\n",
    "    connectome = core.connectom(\n",
    "        task.model, task.prompt, task.metric, intervention, core.BasicStrategy()\n",
    "    )\n",
    "    print(task.short_name, \"corrupt\", corrupt)\n",
    "    core.plot_graphviz_connectome(task.model, task.prompt, connectome, top_k=TOP_K)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
